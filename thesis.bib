
%% Application
@inproceedings{clover,
author = {Tsai, Shin-Yeh and Shan, Yizhou and Zhang, Yiying},
title = {Disaggregating Persistent Memory and Controlling Them Remotely: An Exploration of Passive Disaggregated Key-Value Stores},
year = {2020},
booktitle = {ATC},
}

@inproceedings{sherman,
author = {Wang, Qing and Lu, Youyou and Shu, Jiwu},
title = {Sherman: A Write-Optimized Distributed B+Tree Index on Disaggregated Memory},
year = {2022},
booktitle = {SIGMOD},
}

@inproceedings {aifm,
author = {Zhenyuan Ruan and Malte Schwarzkopf and Marcos K. Aguilera and Adam Belay},
title = {{AIFM}: {High-Performance}, {Application-Integrated} Far Memory},
booktitle = {{{OSDI}}},
year = {2020},
}

@article{ramcloud,
  author = {Ousterhout, John and Agrawal, Parag and Erickson, David and Kozyrakis, Christos and Leverich, Jacob and Mazi{\`e}res, David and Mitra, 
  Subhasish and Narayanan, Aravind and Parulkar, Guru and Rosenblum, Mendel and others},
  title = {{The Case for RAMClouds: Scalable High-performance Storage Entirely in DRAM}},
  journal = {SIGOPS OSR},
  year = {2010}
}

%% Workload
@inproceedings{ycsb_workload,
author = {Cooper, Brian F. and Silberstein, Adam and Tam, Erwin and Ramakrishnan, Raghu and Sears, Russell}, 
title = {{Benchmarking Cloud Serving Systems with YCSB}}, 
year = {2010},
isbn = {9781450300360}, 
publisher = {Association for Computing Machinery}, 
address = {New York, NY, USA}, 
url = {https://doi.org/10.1145/1807128.1807152},
doi = {10.1145/1807128.1807152}, 
booktitle = {Proceedings of the 1st ACM Symposium on Cloud Computing}, 
pages = {143–154}, 
numpages = {12}, 
keywords = {cloud serving database, benchmarking}, 
location = {Indianapolis, Indiana, USA}, 
series = {SoCC '10}
}



%% Disaggregation
@inproceedings{mind,
author = {Lee, Seung-seob and Yu, Yanpeng and Tang, Yupeng and Khandelwal, Anurag and Zhong, Lin and Bhattacharjee, Abhishek},
title = {{MIND: In-Network Memory Management for Disaggregated Data Centers}},
year = {2021},
booktitle = {{{SOSP}}},
}

@inproceedings {legoos,
  author = {Yizhou Shan and Yutong Huang and Yilun Chen and Yiying Zhang},
  title = {{LegoOS: A Disseminated, Distributed OS for Hardware Resource Disaggregation}},
  booktitle = {OSDI},
  year = {2018},
}

@inproceedings{disagg,
  title={{Network Requirements for Resource Disaggregation}},
  author={Gao, Peter Xiang and Narayan, Akshay and Karandikar, Sagar and Carreira, Joao and Han, Sangjin and Agarwal, Rachit and Ratnasamy, Sylvia and Shenker, Scott},
  booktitle={OSDI},
  year={2016}
}

@conference {memdisagg1,
  author = {Krste Asanovi{\'c}},
  title = {{FireBox: A Hardware Building Block for 2020 Warehouse-Scale Computers}},
  year = {2014},
}

@inproceedings{memdisagg2,
  author = {Novakovic, Stanko and Daglis, Alexandros and Bugnion, Edouard and Falsafi, Babak and Grot, Boris},
  title = {{Scale-out NUMA}},
  year = {2014},
  booktitle = {ASPLOS},
}

@inproceedings{memdisagg3,
  title={{Memory Disaggregation: Research Problems and Opportunities}},
  author={Liu, Ling and Cao, Wenqi and Sahin, Semih and Zhang, Qi and Bae, Juhyun and Wu, Yanzhao},
  booktitle={ICDCS},
  year={2019},
}

@inproceedings{memdisagg4,
  author = {Lim, Kevin and Chang, Jichuan and Mudge, Trevor and Ranganathan, Parthasarathy and Reinhardt, Steven K. and Wenisch, Thomas F.},
  title = {{Disaggregated Memory for Expansion and Sharing in Blade Servers}},
  year = {2009},
  booktitle = {ISCA},
}

@INPROCEEDINGS{memdisagg5,
  author={K. {Lim} and Y. {Turner} and J. R. {Santos} and A. {AuYoung} and J. {Chang} and P. {Ranganathan} and T. F. {Wenisch}},
  booktitle={HPCA}, 
  title={{System-level Implications of Disaggregated Memory}}, 
  year={2012},
}

@Inbook{memdisagg6,
  author="Samih, Ahmad and Wang, Ren and Maciocco, Christian and Kharbutli, Mazen and Solihin, Yan",
  title="Collaborative Memories in Clusters: Opportunities and Challenges",
  bookTitle="Transactions on Computational Science XXII",
  year="2014",
}

@inproceedings{nwsupport,
author = {Han, Sangjin and Egi, Norbert and Panda, Aurojit and Ratnasamy, Sylvia and Shi, Guangyu and Shenker, Scott},
title = {{Network Support for Resource Disaggregation in Next-Generation Datacenters}},
year = {2013},
booktitle = {HotNets},
}

@inproceedings{pegasus,
	author    = {Jialin Li and Jacob Nelson and Ellis Michael and Xin Jin and Dan R. K. Ports},
	title     = {{Pegasus: Tolerating Skewed Workloads in Distributed Storage with In-Network Coherence Directories}},
	booktitle = {OSDI},
	year      = {2020}
}

@inproceedings {infiniswap,
  author = {Juncheng Gu and Youngmoon Lee and Yiwen Zhang and Mosharaf Chowdhury and Kang G. Shin},
  title = {{Efficient Memory Disaggregation with Infiniswap}},
  booktitle = {NSDI},
  year = {2017},
}

@inproceedings{disaggfault,
  author = {Carbonari, Amanda and Beschasnikh, Ivan},
  title = {{Tolerating Faults in Disaggregated Datacenters}},
  year = {2017},
  booktitle = {HotNets},
}

@inproceedings {snowset,
author = {Midhul Vuppalapati and Justin Miron and Rachit Agarwal and Dan Truong and Ashish Motivala and Thierry Cruanes},
title = {Building an Elastic Query Engine on Disaggregated Storage},
booktitle = {{USENIX} Networked Systems Design and Implementation ({USENIX} {NSDI}'20)},
}

%% Compiler or Runtime

@inproceedings{wang2020_semeru,
  title = {Semeru: {{A Memory-Disaggregated Managed Runtime}}},
  shorttitle = {Semeru},
  booktitle = {OSDI},
  author = {Wang, Chenxi and Ma, Haoran and Liu, Shi and Li, Yuanqi and Ruan, Zhenyuan and Nguyen, Khanh and Bond, Michael D. and Netravali, Ravi and Kim, Miryung and Xu, Guoqing Harry},
  year = {2020},
  pages = {261--280},
}

@inproceedings{wang2022_memLiner,
  title = {{{MemLiner}}: {{Lining}} up Tracing and Application for a {{Far-Memory-Friendly}} Runtime},
  booktitle = {OSDI},
  author = {Wang, Chenxi and Ma, Haoran and Liu, Shi and Qiao, Yifan and Eyolfson, Jonathan and Navasca, Christian and Lu, Shan and Xu, Guoqing Harry},
  year = {2022},
  month = jul,
  pages = {35--53},
}

@inproceedings{serverlessdisaggregation,
  title={The Serverless Data Center : Hardware Disaggregation Meets Serverless Computing},
  author={Nathan Pemberton and Johann Schleier-Smith},
  year={2019},
  url={https://api.semanticscholar.org/CorpusID:115138760}
}


@misc{gcs,
      title={GCS: Generalized Cache Coherence For Efficient Synchronization}, 
      author={Yanpeng Yu and Seung-seob Lee and Anurag Khandelwal and Lin Zhong},
      year={2023},
      eprint={2301.02576},
      archivePrefix={arXiv},
      primaryClass={cs.DC}
}

@inproceedings{memtis,
author = {Lee, Taehyung and Monga, Sumit Kumar and Min, Changwoo and Eom, Young Ik},
title = {MEMTIS: Efficient Memory Tiering with Dynamic Page Classification and Page Size Determination},
year = {2023},
isbn = {9798400702297},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3600006.3613167},
doi = {10.1145/3600006.3613167},
abstract = {The evergrowing memory demand fueled by datacenter workloads is the driving force behind new memory technology innovations (e.g., NVM, CXL). Tiered memory is a promising solution which harnesses such multiple memory types with varying capacity, latency, and cost characteristics in an effort to reduce server hardware costs while fulfilling memory demand. Prior works on memory tiering make suboptimal (often pathological) page placement decisions because they rely on various heuristics and static thresholds without considering overall memory access distribution. Also, deciding the appropriate page size for an application is difficult as huge pages are not always beneficial as a result of skewed accesses within them. We present Memtis, a tiered memory system that adopts informed decision-making for page placement and page size determination. Memtis leverages access distribution of allocated pages to optimally approximate the hot data set to the fast tier capacity. Moreover, Memtis dynamically determines the page size that allows applications to use huge pages while avoiding their drawbacks by detecting inefficient use of fast tier memory and splintering them if necessary. Our evaluation shows that Memtis outperforms state-of-the-art tiering systems by up to 169.0\% and their best by up to 33.6\%.},
booktitle = {Proceedings of the 29th Symposium on Operating Systems Principles},
pages = {17–34},
numpages = {18},
keywords = {tiered memory management, virtual memory, operating system},
location = {Koblenz, Germany},
series = {SOSP '23}
}

%% General knowledge

%% Programmable network

%% Linux

%% Cache coherece
@inproceedings{pktsched,
  author = {Sivaraman, Anirudh and Subramanian, Suvinay and Alizadeh, Mohammad and Chole, Sharad and Chuang, Shang-Tse and Agrawal, Anurag and Balakrishnan, Hari and Edsall, Tom and Katti, Sachin and McKeown, Nick},
  title = {{Programmable Packet Scheduling at Line Rate}},
  year = {2016},
  booktitle = {SIGCOMM},
}

@misc{p4,
  title = {{P4}},
  howpublished = "\url{https://p4.org/}",
}

@inproceedings{dcp4,
  author = {Sivaraman, Anirudh and Kim, Changhoon and Krishnamoorthy, Ramkumar and Dixit, Advait and Budiu, Mihai},
  title = {{DC.P4: Programming the Forwarding Plane of a Data-Center Switch}},
  year = {2015},
  booktitle = {SOSR},
}

@article{p4paper,
  author = {Bosshart, Pat and Daly, Dan and Gibb, Glen and Izzard, Martin and McKeown, Nick and Rexford, Jennifer and Schlesinger, Cole and Talayco, Dan and Vahdat, Amin and Varghese, George and Walker, David},
  title = {{P4: Programming Protocol-Independent Packet Processors}},
  year = {2014},
  journal = {SIGCOMM CCR},
}
@Manual{progswitch1,
  author = {Intel},
  title = {{Barefoot Networks Unveils Tofino 2, the Next Generation of the World's First Fully P4-Programmable Network Switch ASICs}},
  note = "\url{https://bit.ly/3gmZkBG}",
  year = {2018}
}

@misc{progswitch2,
  title = {{EX9200 Programmable Network Switch - Juniper Networks}},
  howpublished = "\url{https://www.juniper.net/us/en/products-services/switching/ex-series/ex9200/}",
}

@misc{progswitch3,
  title = {{Disaggregation and Programmable Forwarding Planes}},
  howpublished = "\url{https://www.barefootnetworks.com/blog/disaggregation-and-programmable-forwarding-planes/}",
}

@misc{progswitch4,
  title = {{Intel Ethernet Switch FM6000 Series}},
  howpublished = "\url{https://www.intel.com/content/dam/www/public/us/en/documents/product-briefs/ethernet-switch-fm6000-series-brief.pdf}",
}

@misc{prognic1,
  title = {{High-Performance Programmable SmartNICs}},
  howpublished = "\url{https://www.mellanox.com/products/smartnic}",
}

@misc{prognic2,
  title = {{Stingray SmartNIC Adapters and IC}},
  howpublished = "\url{https://www.broadcom.com/products/ethernet-connectivity/smartnic}",
}

@misc{prognic3,
  title = {{SmartNIC Shell: Jumpstart your 100G NIC project}},
  howpublished = "\url{https://www.bittware.com/fpga/smartnic/}",
}

@misc{industry0,
  title = {{High Throughput Computing Data Center Architecture}},
  howpublished = "\url{http://www.huawei.com/ilink/en/download/HW_349607}",
}

@misc{industry1,
  title = {{The Machine: A new kind of computer}},
  howpublished = "\url{https://www.hpl.hp.com/research/systems-research/themachine/}",
}

@misc{industry2,
  title = {{Intel Rack Scale Design: Just what is it?}},
  howpublished = "\url{https://www.datacenterdynamics.com/en/opinions/intel-rack-scale-design-just-what-is-it/}",
}

@misc{industry3,
  title = {{Facebook’s Disaggregated Racks Strategy Provides an Early Glimpse into Next Gen Cloud Computing Data Center Infrastructures}},
  howpublished = "\url{https://dcig.com/2015/01/facebooks-disaggregated-racks-strategy-provides-early-glimpse-next-gen-cloud-computing.html}",
}

@misc{industry4,
  title = {{Rack-scale Computing}},
  howpublished = "\url{https://www.microsoft.com/en-us/research/project/rack-scale-computing/}",
}

@misc{industry5,
  title = {{In Bid for Major Carriers and Service Providers, Dell EMC Rack Scale Infrastructure Offers `Hyperscale Principles'}},
  howpublished = "\url{https://www.enterpriseai.news/2017/09/12/bid-major-carriers-service-providers-dell-emc-rack-scale-infrastructure-offers-hyperscale-principles/}",
}

@misc{terabitethernet,
  title = {{Terabit Ethernet: The New Hot Trend in Data Centers}},
  howpublished = {\url{https://www.lanner-america.com/blog/terabit-ethernet-new-hot-trend-data-centers/}},
  year = {2019}
}

@misc{agg1,
  title = {{Mellanox Scalable Hierarchical Aggregation and Reduction Protocol (SHARP)}},
  howpublished = "\url{https://www.mellanox.com/products/sharp}"
}

@inproceedings{agg2,
  author = {Sapio, Amedeo and Abdelaziz, Ibrahim and Aldilaijan, Abdulla and Canini, Marco and Kalnis, Panos},
  title = {{In-Network Computation is a Dumb Idea Whose Time Has Come}},
  year = {2017},
  booktitle = {HotNets},
}

@misc{agg3,
  title={{Scaling Distributed Machine Learning with In-Network Aggregation}}, 
  author={Amedeo Sapio and Marco Canini and Chen-Yu Ho and Jacob Nelson and Panos Kalnis and Changhoon Kim and Arvind Krishnamurthy and Masoud Moshref and Dan R. K. Ports and Peter Richtárik},
  year={2020},
  eprint={1903.06701},
  archivePrefix={arXiv},
  primaryClass={cs.DC}
}


@misc{msi,
  title = {{MSI Protocol}},
  howpublished = "\url{https://en.wikipedia.org/wiki/MSI_protocol}",
}

@misc{mosi,
  title = {{MOSI Protocol}},
  howpublished = "\url{https://en.wikipedia.org/wiki/MOSI_protocol}",
}

@misc{mesi,
  title = {{MESI Protocol}},
  howpublished = "\url{https://en.wikipedia.org/wiki/MESI_protocol}",
}

@misc{moesi,
  title = {{MOESI Protocol}},
  howpublished = "\url{https://en.wikipedia.org/wiki/MOESI_protocol}",
}

@misc{mesif,
  title = {{MESIF Protocol}},
  howpublished = "\url{https://en.wikipedia.org/wiki/MESIF_protocol}",
}

@misc{pagemigrations,
  title = {{Page Migrations}},
  howpublished = "\url{https://www.kernel.org/doc/html/latest/vm/page_migration.html}"
}

@inproceedings{rmt,
  author = {Bosshart, Pat and Gibb, Glen and Kim, Hun-Seok and Varghese, George and McKeown, Nick and Izzard, Martin and Mujica, Fernando and Horowitz, Mark},
  title = {{Forwarding Metamorphosis: Fast Programmable Match-Action Processing in Hardware for SDN}},
  year = {2013},
  booktitle = {SIGCOMM},
}

@misc{u250,
  title = {Alveo U250 Data Center Accelerator Card},
  howpublished = "\url{https://www.xilinx.com/products/boards-and-kits/alveo/u250.html}",
}

@article{endtoend,
author = {Saltzer, J. H. and Reed, D. P. and Clark, D. D.},
title = {End-to-End Arguments in System Design},
year = {1984},
issue_date = {Nov. 1984},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {2},
number = {4},
issn = {0734-2071},
url = {https://doi.org/10.1145/357401.357402},
doi = {10.1145/357401.357402},
journal = {ACM Trans. Comput. Syst.},
month = {nov},
pages = {277–288},
numpages = {12},
keywords = {design principles, data communication, protocol design}
}



@misc{cxl,
  title        = {{Compute Express Link (CXL)}},
  howpublished = {\url{https://www.computeexpresslink.org/}}
}

@article{cxl_azure,
  title={First-generation Memory Disaggregation for Cloud Platforms},
  author={Li, Huaicheng and Berger, Daniel S and Novakovic, Stanko and Hsu, Lisa and Ernst, Dan and Zardoshti, Pantea and Shah, Monish and Agarwal, Ishwar and Hill, Mark and Fontoura, Marcus and others},
  journal={arXiv preprint arXiv:2203.00241},
  year={2022}
}

@misc{cxlcentric,
      title={A Case for CXL-Centric Server Processors}, 
      author={Albert Cho and Anish Saxena and Moinuddin Qureshi and Alexandros Daglis},
      year={2023},
      eprint={2305.05033},
      archivePrefix={arXiv},
      primaryClass={cs.AR}
}


@article{pond,
  title={Pond: CXL-Based Memory Pooling Systems for Cloud Platforms},
  author={Huaicheng Li and Daniel S. Berger and Stanko Novakovic and Lisa R. Hsu and Dan Ernst and Pantea Zardoshti and Monish Shah and Samir Rajadnya and Scott Lee and Ishwar Agarwal and Mark D. Hill and Marcus Fontoura and Ricardo Bianchini},
  journal={Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2},
  year={2022},
  url={https://api.semanticscholar.org/CorpusID:252907213}
}

@inproceedings{tpp,
author = {Maruf, Hasan Al and Wang, Hao and Dhanotia, Abhishek and Weiner, Johannes and Agarwal, Niket and Bhattacharya, Pallab and Petersen, Chris and Chowdhury, Mosharaf and Kanaujia, Shobhit and Chauhan, Prakash},
title = {TPP: Transparent Page Placement for CXL-Enabled Tiered-Memory},
year = {2023},
isbn = {9781450399180},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3582016.3582063},
doi = {10.1145/3582016.3582063},
abstract = {The increasing demand for memory in hyperscale applications has led to memory becoming a large portion of the overall datacenter spend. The emergence of coherent interfaces like CXL enables main memory expansion and offers an efficient solution to this problem. In such systems, the main memory can constitute different memory technologies with varied characteristics. In this paper, we characterize memory usage patterns of a wide range of datacenter applications across the server fleet of Meta. We, therefore, demonstrate the opportunities to offload colder pages to slower memory tiers for these applications. Without efficient memory management, however, such systems can significantly degrade performance. We propose a novel OS-level application-transparent page placement mechanism (TPP) for CXL-enabled memory. TPP employs a lightweight mechanism to identify and place hot/cold pages to appropriate memory tiers. It enables a proactive page demotion from local memory to CXL-Memory. This technique ensures a memory headroom for new page allocations that are often related to request processing and tend to be short-lived and hot. At the same time, TPP can promptly promote performance-critical hot pages trapped in the slow CXL-Memory to the fast local memory, while minimizing both sampling overhead and unnecessary migrations. TPP works transparently without any application-specific knowledge and can be deployed globally as a kernel release. We evaluate TPP with diverse memory-sensitive workloads in the production server fleet with early samples of new x86 CPUs with CXL 1.1 support. TPP makes a tiered memory system performant as an ideal baseline (&lt;1\% gap) that has all the memory in the local tier. It is 18\% better than today’s Linux, and 5–17\% better than existing solutions including NUMA Balancing and AutoTiering. Most of the TPP patches have been merged in the Linux v5.18 release while the remaining ones are just pending for more discussion.},
booktitle = {Proceedings of the 28th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 3},
pages = {742–755},
numpages = {14},
keywords = {Operating Systems, Memory Management, Datacenters, Tiered-Memory, Heterogeneous System, CXL-Memory},
location = {Vancouver, BC, Canada},
series = {ASPLOS 2023}
}

@inproceedings {mt2,
author = {Jifei Yi and Benchao Dong and Mingkai Dong and Ruizhe Tong and Haibo Chen},
title = {{MT\^2}: Memory Bandwidth Regulation on Hybrid {NVM/DRAM} Platforms},
booktitle = {20th USENIX Conference on File and Storage Technologies (FAST 22)},
year = {2022},
isbn = {978-1-939133-26-7},
address = {Santa Clara, CA},
pages = {199--216},
url = {https://www.usenix.org/conference/fast22/presentation/yi-mt2},
publisher = {USENIX Association},
month = feb,
}

@inproceedings {nyxcache,
author = {Kan Wu and Kaiwei Tu and Yuvraj Patel and Rathijit Sen and Kwanghyun Park and Andrea Arpaci-Dusseau and Remzi Arpaci-Dusseau},
title = {{NyxCache}: Flexible and Efficient Multi-tenant Persistent Memory Caching},
booktitle = {20th USENIX Conference on File and Storage Technologies (FAST 22)},
year = {2022},
isbn = {978-1-939133-26-7},
address = {Santa Clara, CA},
pages = {1--16},
url = {https://www.usenix.org/conference/fast22/presentation/wu},
publisher = {USENIX Association},
month = feb,
}

@inproceedings{numalloc,
author = {Yang, Hanmei and Zhao, Xin and Zhou, Jin and Wang, Wei and Kundu, Sandip and Wu, Bo and Guan, Hui and Liu, Tongping},
title = {NUMAlloc: A Faster NUMA Memory Allocator},
year = {2023},
isbn = {9798400701795},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3591195.3595276},
doi = {10.1145/3591195.3595276},
abstract = {The NUMA architecture accommodates the hardware trend of an increasing number of CPU cores. It requires the cooperation of memory allocators to achieve good performance for multithreaded applications. Unfortunately, existing allocators do not support NUMA architecture well. This paper presents a novel memory allocator – NUMAlloc, that is designed for the NUMA architecture. is centered on a binding-based memory management. On top of it, proposes an “origin-aware memory management” to ensure the locality of memory allocations and deallocations, as well as a method called “incremental sharing” to balance the performance benefits and memory overhead of using transparent huge pages. According to our extensive evaluation, NUMAlloc has the best performance among all evaluated allocators, running 15.7\% faster than the second-best allocator (mimalloc), and 20.9\% faster than the default Linux allocator with reasonable memory overhead. NUMAlloc is also scalable to 128 threads and is ready for deployment.},
booktitle = {Proceedings of the 2023 ACM SIGPLAN International Symposium on Memory Management},
pages = {97–110},
numpages = {14},
keywords = {NUMA Architecture, Memory Allocation},
location = {Orlando, FL, USA},
series = {ISMM 2023}
}

@ARTICLE{smt,
  author={Kim, Kyungsan and Kim, Hyunseok and So, Jinin and Lee, Wonjae and Im, Junhyuk and Park, Sungjoo and Cho, Jeonghyeon and Song, Hoyoung},
  journal={IEEE Micro}, 
  title={SMT: Software-Defined Memory Tiering for Heterogeneous Computing Systems With CXL Memory Expander}, 
  year={2023},
  volume={43},
  number={2},
  pages={20-29},
  doi={10.1109/MM.2023.3240774}}

@inproceedings {empiricalPM,
author = {Jian Yang and Juno Kim and Morteza Hoseinzadeh and Joseph Izraelevitz and Steve Swanson},
title = {An Empirical Guide to the Behavior and Use of Scalable Persistent Memory},
booktitle = {18th USENIX Conference on File and Storage Technologies (FAST 20)},
year = {2020},
isbn = {978-1-939133-12-0},
address = {Santa Clara, CA},
pages = {169--182},
url = {https://www.usenix.org/conference/fast20/presentation/yang},
publisher = {USENIX Association},
month = feb,
}

@ARTICLE{cxltradeoff,
  author={Berger, Daniel S. and Ernst, Daniel and Li, Huaicheng and Zardoshti, Pantea and Shah, Monish and Rajadnya, Samir and Lee, Scott and Hsu, Lisa and Agarwal, Ishwar and Hill, Mark D. and Bianchini, Ricardo},
  journal={IEEE Micro}, 
  title={Design Tradeoffs in CXL-Based Memory Pools for Public Cloud Platforms}, 
  year={2023},
  volume={43},
  number={2},
  pages={30-38},
  doi={10.1109/MM.2023.3241586}}

@misc{demystify,
      title={Demystifying CXL Memory with Genuine CXL-Ready Systems and Devices}, 
      author={Yan Sun and Yifan Yuan and Zeduo Yu and Reese Kuper and Ipoom Jeong and Ren Wang and Nam Sung Kim},
      year={2023},
      eprint={2303.15375},
      archivePrefix={arXiv},
      primaryClass={cs.PF}
}

@misc{Interleavepatch,
  title = {{J. Weiner. [PATCH] mm: mempolicy: N:M interleave policy for tiered memory nodes.}},
  howpublished = "\url{https://lore.kernel.org/linux-mm/YqD0%2FtzFwXvJ1gK6@cmpxchg.org/T/}",
}

@misc{mlc,
  title = {{V. Viswanathan, K. Kumar, and T. Willhalm. "Intel® Memory Latency Checker v3.10"}},
  howpublished = "\url{https://www.intel.com/content/www/us/en/developer/articles/tool/intelr-memory-latency-checker.html}",
}

@inproceedings {directcxl,
author = {Donghyun Gouk and Sangwon Lee and Miryeong Kwon and Myoungsoo Jung},
title = {Direct Access, {High-Performance} Memory Disaggregation with {DirectCXL}},
booktitle = {2022 USENIX Annual Technical Conference (USENIX ATC 22)},
year = {2022},
isbn = {978-1-939133-29-65},
address = {Carlsbad, CA},
pages = {287--294},
url = {https://www.usenix.org/conference/atc22/presentation/gouk},
publisher = {USENIX Association},
month = jul,
}


@misc{A1000,
  title = {{Leo Memory Connectivity Platform for CXL 1.1 and 2.0}},
  howpublished = "\url{https://www.asteralabs.com/wp-content/uploads/2022/08/Astera_Labs_Leo_Aurora_Product_FINAL.pdf}",
}

@misc{SPR,
  title = {{Intel Corporation. Intel launches $\text{4}^{th}$ gen xeon scalable processors, max series cpus.}},
  howpublished = "\url{https://www.intel.com/content/www/us/en/newsroom/news/}",
}

@misc(EPYC,
  title = {{AMD. AMD EPYC 9004 Series Server Processors}},
  howpublished = "\url{https://www.amd.com/en/processors/epyc-9004-series}",
)

@misc{mxc,
  title = {{Montage Technology. Cxl memory expander controller (mxc).}},
  howpublished = "\url{https://www.montage-tech.com/MXC, accessed in 2023.}",
}

@misc{snc,
    title = {{David L Mulnix. Intel® Xeon® Processor Scalable Family Technical Overview}},
    howpublished = "\url{https://www.intel.com/content/www/us/en/developer/articles/technical/xeon-processor-scalable-family-technical-overview.html}",
}

@misc{intelfpga,
  title = {{Intel Corporation. Intel Agilex® 7 FPGA and SoC FPGA I-Series}},
  howpublished = "\url{https://www.intel.com/content/www/us/en/products/details/fpga/agilex/7/i-series.html}",
}

@misc{q8chat,
  title = {{Julien Simon.Smaller is Better: Q8-Chat LLM is an Efficient Generative AI Experience on Intel® Xeon® Processors}},
  howpublished = "\url{https://www.intel.com/content/www/us/en/developer/articles/case-study/q8-chat-efficient-generative-ai-experience-xeon.html}",
}

@misc{emerald_rapids,
    title = {{Intel Corporation. Intel Unveils Future-Generation Xeon with Robust Performance and Efficiency Architectures}},
    howpublished = "\url{https://www.intel.com/content/www/us/en/newsroom/news/intel-unveils-future-generation-xeon.html}",
}

@misc{pcm,
    title = {{Intel Corporation. Intel® Performance Counter Monitor (Intel® PCM)}},
    howpublished = "\url{https://github.com/intel/pcm}",
}

@inproceedings{FlatFlash,
author = {Abulila, Ahmed and Mailthody, Vikram Sharma and Qureshi, Zaid and Huang, Jian and Kim, Nam Sung and Xiong, Jinjun and Hwu, Wen-mei},
title = {FlatFlash: Exploiting the Byte-Accessibility of SSDs within a Unified Memory-Storage Hierarchy},
year = {2019},
isbn = {9781450362405},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3297858.3304061},
doi = {10.1145/3297858.3304061},
booktitle = {Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {971–985},
numpages = {15},
keywords = {byte-addressable ssd, unified memory management, page promotion, data persistence},
location = {Providence, RI, USA},
series = {ASPLOS '19}
}

@inproceedings {cxl-ssd,
author = {Shao-Peng Yang and Minjae Kim and Sanghyun Nam and Juhyung Park and Jin-yong Choi and Eyee Hyun Nam and Eunji Lee and Sungjin Lee and Bryan S. Kim},
title = {Overcoming the Memory Wall with {CXL-Enabled} {SSDs}},
booktitle = {2023 USENIX Annual Technical Conference (USENIX ATC 23)},
year = {2023},
isbn = {978-1-939133-35-9},
address = {Boston, MA},
pages = {601--617},
url = {https://www.usenix.org/conference/atc23/presentation/yang-shao-peng},
publisher = {USENIX Association},
month = jul
}

@INPROCEEDINGS{PSACS,
  author={Zou, Chen and Zhang, Hui and Chien, Andrew A. and Seok Ki, Yang},
  booktitle={2021 IEEE 39th International Conference on Computer Design (ICCD)}, 
  title={PSACS: Highly-Parallel Shuffle Accelerator on Computational Storage}, 
  year={2021},
  volume={},
  number={},
  pages={480-487},
  doi={10.1109/ICCD53106.2021.00080}}

@misc{redis,
    title = {{Redis. }},
    howpublished = "\url{https://redis.io/}",
}

@misc{googlecloud,
    title = {{Google Cloud. Memory management best practices}},
    howpublished = "\url{https://cloud.google.com/memorystore/docs/redis/memory-management-best-practices}",
}

@misc{manageredis,
    title = {{Tecton.ai. Managing your Redis Cluster}},
    howpublished = "\url{https://docs.tecton.ai/docs/0.5/setting-up-tecton/setting-up-other-components/managing-your-redis-cluster}",
}

@misc{H100,
    title = {{NVIDIA. NVIDIA H100 Tensor Core GPU}},
    howpublished = "\url{https://www.nvidia.com/en-gb/data-center/h100/}"},
}

@INPROCEEDINGS{amx,
  author={Nassif, Nevine and Munch, Ashley O. and Molnar, Carleton L. and Pasdast, Gerald and Lyer, Sitaraman V. and Yang, Zibing and Mendoza, Oscar and Huddart, Mark and Venkataraman, Srikrishnan and Kandula, Sireesha and Marom, Rafi and Kern, Alexandra M. and Bowhill, Bill and Mulvihill, David R. and Nimmagadda, Srikanth and Kalidindi, Varma and Krause, Jonathan and Haq, Mohammad M. and Sharma, Roopali and Duda, Kevin},
  booktitle={2022 IEEE International Solid- State Circuits Conference (ISSCC)}, 
  title={Sapphire Rapids: The Next-Generation Intel Xeon Scalable Processor}, 
  year={2022},
  volume={65},
  number={},
  pages={44-46},
  doi={10.1109/ISSCC42614.2022.9731107}}

@inproceedings{YCSB,
author = {Cooper, Brian F. and Silberstein, Adam and Tam, Erwin and Ramakrishnan, Raghu and Sears, Russell},
title = {Benchmarking Cloud Serving Systems with YCSB},
year = {2010},
isbn = {9781450300360},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1807128.1807152},
doi = {10.1145/1807128.1807152},
abstract = {While the use of MapReduce systems (such as Hadoop) for large scale data analysis has been widely recognized and studied, we have recently seen an explosion in the number of systems developed for cloud data serving. These newer systems address "cloud OLTP" applications, though they typically do not support ACID transactions. Examples of systems proposed for cloud serving use include BigTable, PNUTS, Cassandra, HBase, Azure, CouchDB, SimpleDB, Voldemort, and many others. Further, they are being applied to a diverse range of applications that differ considerably from traditional (e.g., TPC-C like) serving workloads. The number of emerging cloud serving systems and the wide range of proposed applications, coupled with a lack of apples-to-apples performance comparisons, makes it difficult to understand the tradeoffs between systems and the workloads for which they are suited. We present the "Yahoo! Cloud Serving Benchmark" (YCSB) framework, with the goal of facilitating performance comparisons of the new generation of cloud data serving systems. We define a core set of benchmarks and report results for four widely used systems: Cassandra, HBase, Yahoo!'s PNUTS, and a simple sharded MySQL implementation. We also hope to foster the development of additional cloud benchmark suites that represent other classes of applications by making our benchmark tool available via open source. In this regard, a key feature of the YCSB framework/tool is that it is extensible--it supports easy definition of new workloads, in addition to making it easy to benchmark new systems.},
booktitle = {Proceedings of the 1st ACM Symposium on Cloud Computing},
pages = {143–154},
numpages = {12},
keywords = {benchmarking, cloud serving database},
location = {Indianapolis, Indiana, USA},
series = {SoCC '10}
}

@misc{cpuinference,
    title = {{Timothy P. Morgan. WHY AI INFERENCE WILL REMAIN LARGELY ON THE CPU}},
    howpublished = "\url{https://www.nextplatform.com/2023/04/05/why-ai-inference-will-remain-largely-on-the-cpu/}",
}

@misc{intelbenchmark,
    title = {{Intel Corporation. 4th Generation Intel® Xeon® Scalable Processors Performance.}},
    howpublished = "\url{https://edc.intel.com/content/www/us/en/products/performance/benchmarks/4th-generation-intel-xeon-scalable-processors/}",
}

@misc{vllm,
      title={Efficient Memory Management for Large Language Model Serving with PagedAttention}, 
      author={Woosuk Kwon and Zhuohan Li and Siyuan Zhuang and Ying Sheng and Lianmin Zheng and Cody Hao Yu and Joseph E. Gonzalez and Hao Zhang and Ion Stoica},
      year={2023},
      eprint={2309.06180},
      archivePrefix={arXiv},
      primaryClass={cs.LG}
}

@misc{lightllm,
    title={{Lightllm A Light and Fast Inference Service for LLM}},
    howpublished = "\url{https://github.com/ModelTC/lightllm}",
}

@misc{amdepyc,
    title={{Videocardz. AMD next-gen socket SP7 reportedly launches alongside Venice data-center CPUs}},
    howpublished = "\url{https://videocardz.com/newz/amd-epyc-venice-with-zen6-cpu-cores-reportedly-uses-new-sp7-socket}",
}

@misc{redis-benchmark,
    title={{Redis benchmark. Using the redis-benchmark utility on a Redis server.}},
    howpublished = "\url{https://lore.kernel.org/lkml/CAAPL-u9Wv+nH1VOZTj=9p9S70Y3Qz3+63EkqncRDdHfubsrjfw@mail.gmail.com/}",
}

@inproceedings{fpgaasic,
author = {Kuon, Ian and Rose, Jonathan},
title = {Measuring the Gap between FPGAs and ASICs},
year = {2006},
isbn = {1595932925},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1117201.1117205},
doi = {10.1145/1117201.1117205},
abstract = {This paper presents experimental measurements of the differences between a 90nm CMOS FPGA and 90nm CMOS Standard Cell ASICs in terms of logic density, circuit speed and power consumption. We are motivated to make these measurements to enable system designers to make better informed hoices between these two media and to give insight to FPGA makers on the deficiencies to attack and thereby improve FPGAs. In the paper, we describe the methodology by which the measurements were obtained and we show that, for circuits containing only combinational logic and flip-flops, the ratio of silicon area required to implement them in FPGAs and ASICs is on average 40. Modern FPGAs also contain "hard" blocks such as multiplier/accumulators and block memories and we find that these blocks reduce this average area gap significantly to as little as 21. The ratio of critical path delay, from FPGA to ASIC, is roughly 3 to 4, with less influence from block memory and hard multipliers. The dynamic power onsumption ratio is approximately 12 times and, with hard blocks, this gap generally becomes smaller.},
booktitle = {Proceedings of the 2006 ACM/SIGDA 14th International Symposium on Field Programmable Gate Arrays},
pages = {21–30},
numpages = {10},
keywords = {FPGA, ASIC, area comparison, power comparison, delay comparison},
location = {Monterey, California, USA},
series = {FPGA '06}
}

@misc{intelsnc,
    title={{Intel Xeon Processor Scalable Family Technical Overview.}},
    howpublished = "\url{https://www.intel.com/content/www/us/en/developer/articles/technical/xeon-processor-scalable-family-technical-overview.html}",
}

@misc{gh200,
title={{Nvidia GH200 Datasheet.}},
howpublished="\url{https://resources.nvidia.com/en-us-dgx-gh200/nvidia-grace-hopper-superchip-datasheet}",
}
@misc{appleuma,
title={{Apple Introduces M2 Ultra.}},
howpublished="\url{https://www.apple.com/newsroom/2023/06/apple-introduces-m2-ultra/}",
}
@misc{pcieopt,
title={{PCI-SIG explores an optical interconnect for higher PCIe performance}},
howpublished="\url{https://www.eenewseurope.com/en/pci-sig-explores-an-optical-connections-for-higher-pcie-performance/}",
}
@misc{uec,
title={{Ultra Ethernet Consortium.}},
howpublished="\url{https://ultraethernet.org/}",
}

@inproceedings{tpuv4,
author = {N. Jouppi and et al.},
title = {TPU v4: An Optically Reconfigurable Supercomputer for Machine Learning with Hardware Support for Embeddings},
year = {2023},
booktitle = {Proceedings of the 50th Annual International Symposium on Computer Architecture},
}

@misc{cxl-centric,
title={{A Case for CXL-Centric Server Processors.}},
author={A. Cho and et al.},
howpublished="\url{https://arxiv.org/abs/2305.05033}",
}

@inproceedings{moe-iclr17,
author = {N. Shazeer and et al.},
title = {Outrageously Large Neural Networks: The Sparsely-Gated Mixture-of-Experts Layer},
year = {2017},
booktitle = {The 5th International Conference on Learning Representations},
}

@misc{gpt4,
title={{GPT-4 Architecture, Infrastructure, Training Dataset, Costs, Vision, MoE.}},
author={D. Patel, G. Wong},
year={2023},
howpublished="\url{https://www.semianalysis.com/p/gpt-4-architecture-infrastructure}",
}

@inproceedings{cxldatabase,
author = {Ahn, Minseon and Chang, Andrew and Lee, Donghun and Gim, Jongmin and Kim, Jungmin and Jung, Jaemin and Rebholz, Oliver and Pham, Vincent and Malladi, Krishna and Ki, Yang Seok},
title = {Enabling CXL Memory Expansion for In-Memory Database Management Systems},
year = {2022},
isbn = {9781450393782},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3533737.3535090},
doi = {10.1145/3533737.3535090},
abstract = {Limited memory volume is always a performance bottleneck in an in-memory database management system (IMDBMS) as the data size keeps increasing. To overcome the physical memory limitation, heterogeneous and disaggregated computing platforms are proposed, such as Gen-Z, CCIX, OpenCAPI, and CXL. In this work, we introduce flexible CXL memory expansion using a CXL type 3 prototype and evaluate its performance in an IMDBMS. Our evaluation shows that CXL memory devices interfaced with PCIe Gen5 are appropriate for memory expansion with nearly no throughput degradation in OLTP workloads and less than 8\% throughput degradation in OLAP workloads. Thus, CXL memory is a good candidate for memory expansion with lower TCO in IMDBMSs.},
booktitle = {Proceedings of the 18th International Workshop on Data Management on New Hardware},
articleno = {8},
numpages = {5},
keywords = {CXL, Database Management Systems, Compute Express Link, In-Memory Database, DBMS},
location = {Philadelphia, PA, USA},
series = {DaMoN '22}
}

@INPROCEEDINGS{snoopfilter,
  author={Sharma, Debendra Das},
  booktitle={2022 IEEE Symposium on High-Performance Interconnects (HOTI)}, 
  title={Compute Express Link®: An open industry-standard interconnect enabling heterogeneous data-centric computing}, 
  year={2022},
  volume={},
  number={},
  pages={5-12},
  doi={10.1109/HOTI55740.2022.00017}}

@article{sparkmemory,
author = {Zhang, Xuechen and Khanal, Ujjwal and Zhao, Xinghui and Ficklin, Stephen},
title = {Making Sense of Performance in In-Memory Computing Frameworks for Scientific Data Analysis: A Case Study of the Spark System},
year = {2018},
issue_date = {Oct 2018},
publisher = {Academic Press, Inc.},
address = {USA},
volume = {120},
number = {C},
issn = {0743-7315},
url = {https://doi.org/10.1016/j.jpdc.2017.10.016},
doi = {10.1016/j.jpdc.2017.10.016},
journal = {J. Parallel Distrib. Comput.},
month = {oct},
pages = {369–382},
numpages = {14},
keywords = {SciDB, Spark, In-memory computing, Scientific data analytics}
}

@INPROCEEDINGS{hybridcxleval,
  author={Yang, Qirui and Jin, Runyu and Davis, Bridget and Inupakutika, Devasena and Zhao, Ming},
  booktitle={2022 IEEE International Conference on Networking, Architecture and Storage (NAS)}, 
  title={Performance Evaluation on CXL-enabled Hybrid Memory Pool}, 
  year={2022},
  volume={},
  number={},
  pages={1-5},
  doi={10.1109/NAS55553.2022.9925356}}

@misc{h100amazon,
title={{Nvidia H100 80GB on Amazon.}},
year={2023},
howpublished="\url{https://www.amazon.com/Tesla-NVIDIA-Learning-Compute-Graphics/dp/B0C3XH4QSJ}",
}

@misc{msssd,
title={{Samsung Memory Semantic SSD.}},
year={2023},
howpublished="\url{https://samsungmsl.com/ms-ssd/}",
}

@INPROCEEDINGS{elasticcomputing,
  author={Yi, Sangho and Kondo, Derrick and Andrzejak, Artur},
  booktitle={2010 IEEE 3rd International Conference on Cloud Computing}, 
  title={Reducing Costs of Spot Instances via Checkpointing in the Amazon Elastic Compute Cloud}, 
  year={2010},
  volume={},
  number={},
  pages={236-243},
  doi={10.1109/CLOUD.2010.35}}

@misc{awsm7a,
title={{Amazon EC2 M7a Instances}},
year={2023},
howpublished="\url{https://aws.amazon.com/ec2/instance-types/m7a/}",
}

@misc{awsm7i,
title={{Amazon EC2 M7i Instances}},
year={2023},
howpublished="\url{https://aws.amazon.com/ec2/instance-types/m7i/}",
}

@misc{redisenterprise,
title={{Redis enterprise}},
year={2023},
howpublished="\url{https://redis.io/docs/about/redis-enterprise/}",
}

@misc{numaautobalancing,
title={{NUMA balancing: optimize memory placement for memory tiering system}},
howpublished="\url{https://lore.kernel.org/linux-mm/20220221084529.1052339-1-ying.huang@intel.com/}",
}

@misc{tpppatch,
title={{Transparent Page Placement for Tiered-Memory}},
howpublished = "\url{https://lore.kernel.org/all/cover.1637778851.git.hasanalmaruf@fb.com/}",
}

@misc{redisautotiering,
title={{Auto Tiering Extend Redis Enterprise databases beyond DRAM limits}},
howpublished = "\url{https://redis.com/redis-enterprise/technology/auto-tiering/#:~:text=Redis%20Enterprise's%20auto%20tiering%20lets,compared%20to%20only%20DRAM%20deployments.}",
}


@inproceedings {caerus,
author = {Hong Zhang and Yupeng Tang and Anurag Khandelwal and Jingrong Chen and Ion Stoica},
title = {Caerus: {NIMBLE} Task Scheduling for Serverless Analytics},
booktitle = {18th USENIX Symposium on Networked Systems Design and Implementation (NSDI 21)},
year = {2021},
isbn = {978-1-939133-21-2},
pages = {653--669},
url = {https://www.usenix.org/conference/nsdi21/presentation/zhang-hong},
publisher = {USENIX Association},
month = apr
}

@inproceedings {shepherd,
author = {Hong Zhang and Yupeng Tang and Anurag Khandelwal and Ion Stoica},
title = {{SHEPHERD}: Serving {DNNs} in the Wild},
booktitle = {20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23)},
year = {2023},
isbn = {978-1-939133-33-5},
address = {Boston, MA},
pages = {787--808},
url = {https://www.usenix.org/conference/nsdi23/presentation/zhang-hong},
publisher = {USENIX Association},
month = apr
}

@inproceedings{jiffy,
author = {Khandelwal, Anurag and Tang, Yupeng and Agarwal, Rachit and Akella, Aditya and Stoica, Ion},
title = {Jiffy: Elastic Far-Memory for Stateful Serverless Analytics},
year = {2022},
isbn = {9781450391627},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3492321.3527539},
doi = {10.1145/3492321.3527539},
abstract = {Stateful serverless analytics can be enabled using a remote memory system for inter-task communication, and for storing and exchanging intermediate data. However, existing systems allocate memory resources at job granularity---jobs specify their memory demands at the time of the submission; and, the system allocates memory equal to the job's demand for the entirety of its lifetime. This leads to resource underutilization and/or performance degradation when intermediate data sizes vary during job execution.This paper presents Jiffy, an elastic far-memory system for stateful serverless analytics that meets the instantaneous memory demand of a job at seconds timescales. Jiffy efficiently multiplexes memory capacity across concurrently running jobs, reducing the overheads of reads and writes to slower persistent storage, resulting in 1.6 -- 2.5\texttimes{} improvements in job execution time over production workloads. Jiffy implementation currently runs on Amazon EC2, enables a wide variety of distributed programming models including MapReduce, Dryad, StreamScope, and Piccolo, and natively supports a large class of analytics applications on AWS Lambda.},
booktitle = {Proceedings of the Seventeenth European Conference on Computer Systems},
pages = {697–713},
numpages = {17},
keywords = {function-as-a-service, serverless computing, far-memory, data analytics},
location = {Rennes, France},
series = {EuroSys '22}
}

@misc{chase,
title={{CHASE: Accelerating Distributed Pointer-Traversals on Disaggregated Memory}},
year={2023},
howpublished="\url{https://arxiv.org/pdf/2305.02388.pdf}",
}





@misc{dataintensive,
  title = "The Cloud Native Convergence: A New Era of Data-Intensive Applications", 
  author = "Dez Blanchfield", 
  howpublished = {\url{https://elnion.com/2023/06/05/the-cloud-native-convergence-a-new-era-of-data-intensive-applications/}}
}


@article{nvlink,
  title={Evaluating modern gpu interconnect: Pcie, nvlink, nv-sli, nvswitch and gpudirect},
  author={Li, Ang and Song, Shuaiwen Leon and Chen, Jieyang and Li, Jiajia and Liu, Xu and Tallent, Nathan R and Barker, Kevin J},
  journal={IEEE Transactions on Parallel and Distributed Systems},
  volume={31},
  number={1},
  pages={94--110},
  year={2019},
  publisher={IEEE}
}


%% Compute offloading
@inproceedings{zhang2022_teleport,
  title = {Optimizing Data-Intensive Systems in Disaggregated Data Centers with {{TELEPORT}}},
  booktitle = {SIGMOD},
  author = {Zhang, Qizhen and Chen, Xinyi and Sankhe, Sidharth and Zheng, Zhilei and Zhong, Ke and Angel, Sebastian and Chen, Ang and Liu, Vincent and Loo, Boon Thau},
  year = {2022},
  pages = {1345--1359},
}

@INPROCEEDINGS{impica,
  author={Hsieh, Kevin and Khan, Samira and Vijaykumar, Nandita and Chang, Kevin K. and Boroumand, Amirali and Ghose, Saugata and Mutlu, Onur},
  booktitle={International Conference on Computer Design (ICCD)}, 
  title={Accelerating pointer chasing in 3D-stacked memory: Challenges, mechanisms, evaluation}, 
  year={2016},
}

@inproceedings{strom,
author = {Sidler, David and Wang, Zeke and Chiosa, Monica and Kulkarni, Amit and Alonso, Gustavo},
title = {StRoM: Smart Remote Memory},
year = {2020},
booktitle = {{{EuroSys}}},
}

@inproceedings{clio,
  author = {Guo, Zhiyuan and Shan, Yizhou and Luo, Xuhao and Huang, Yutong and Zhang, Yiying},
  title = {Clio: A Hardware-Software Co-Designed Disaggregated Memory System},
  year = {2022},
  booktitle = {{{ASPLOS}}},
}

@inproceedings {redn,
author = {Waleed Reda and Marco Canini and Dejan Kosti{\'c} and Simon Peter},
title = {{RDMA} is Turing complete, we just did not know it yet!},
booktitle = {{{NSDI}}},
year = {2022},
}

@inproceedings{rmc_hotnets20,
  title = {Remote Memory Calls},
  booktitle = {Proceedings of the 19th {{ACM}} Workshop on Hot Topics in Networks},
  author = {Amaro, Emmanuel and Luo, Zhihong and Ousterhout, Amy and Krishnamurthy, Arvind and Panda, Aurojit and Ratnasamy, Sylvia and Shenker, Scott},
  year = {2020},
  pages = {38--44},
}


@inproceedings{smartnic,
  author = {Daniel Firestone and Andrew Putnam and Sambhrama Mundkur and Derek Chiou and Alireza Dabagh and Mike Andrewartha and Hari Angepat and Vivek Bhanu and Adrian Caulfield and Eric Chung and Harish Kumar Chandrappa and Somesh Chaturmohta and Matt Humphrey and Jack Lavier and Norman Lam and Fengfen Liu and Kalin Ovtcharov and Jitu Padhye and Gautham Popuri and Shachar Raindel and Tejas Sapre and Mark Shaw and Gabriel Silva and Madhan Sivakumar and Nisheeth Srivastava and Anshuman Verma and Qasim Zuhair and Deepak Bansal and Doug Burger and Kushagra Vaid and David A. Maltz and Albert Greenberg},
  title = {{Azure Accelerated Networking: SmartNICs in the Public Cloud}},
  booktitle = {NSDI},
  year = {2018},
}

% DMS
@article{gam, 
author = {Cai, Qingchao and Guo, Wentian and Zhang, Hao and Agrawal, Divyakant and Chen, Gang and Ooi, Beng Chin and Tan, Kian-Lee and Teo, Yong Meng and Wang, Sheng}, 
title = {{Efficient Distributed Memory Management with RDMA and Caching}}, 
year = {2018},
issue_date = {July 2018}, 
publisher = {VLDB Endowment}, 
volume = {11}, 
number = {11}, 
issn = {2150-8097}, 
url = {https://doi.org/10.14778/3236187.3236209}, 
doi = {10.14778/3236187.3236209}, 
journal = {Proc. VLDB Endow.}, 
month = jul, 
pages = {1604–1617}, 
numpages = {14}
}

@inproceedings{dsm1,
 author = {Carter, John B. and Bennett, John K. and Zwaenepoel, Willy},
 title = {Implementation and Performance of Munin},
 booktitle = {ACM Symposium on Operating Systems Principles (SOSP)},
 year = {1991},
 pages = {152--164},
}

@article{dsm2,
 author = {Li, Kai and Hudak, Paul},
 title = {Memory Coherence in Shared Virtual Memory Systems},
 journal = {ACM Transactions on Computer Systems (TOCS)},
 volume = {7},
 number = {4},
 year = {1989},
 pages = {321--359},
}

@article{dsm3,
 author = {Nitzberg, Bill and Lo, Virginia},
 title = {{Distributed Shared Memory: A Survey of Issues and Algorithms}},
 journal = {Computer},
 volume = {24},
 number = {8},
 year = {1991},
 pages = {52--60},
 numpages = {9},
}

%% Pulse
@misc{stl,
  title        = {{Standard containers}},
  howpublished = {\url{https://cplusplus.com/reference/stl/}}
}

@misc{boost,
  title        = {{Boost library}},
  howpublished = {\url{https://www.boost.org/}}
}

@misc{btree,
  title        = {{Google BTree}},
  howpublished = {\url{https://code.google.com/archive/p/cpp-btree/}}
}

@misc{google-btree,
  title        = {{Google BTree}},
  howpublished = {\url{https://code.google.com/archive/p/cpp-btree/}}
}


@misc{javaiterator,
  title        = {{Java iterator}},
  howpublished = {\url{https://www.w3schools.com/java/java_iterator.asp}}
}

@misc{c++iterator,
  title        = {{C++ std::iterator}},
  howpublished = {\url{https://en.cppreference.com/w/cpp/iterator/iterator}}
}

@misc{dpdk,
  title        = {{DPDK}},
  howpublished = {\url{https://www.dpdk.org/}}
}

@misc{powerdata,
  title        = {{Berkeley Lab Micro-Phasor Measurement Unit Data}},
  howpublished = {\url{https://powerdata-download.lbl.gov/data/}}
}
@misc{llvm,
  title        = {{The LLVM Compiler Infrastructure}},
  howpublished = {\url{https://llvm.org/}}
}

@misc{xilinx_network,
  title        = {{XUP Vitis Network Example (VNx)}},
  howpublished = {\url{https://github.com/Xilinx/xup_vitis_network_example}}
}

@misc{xilinx_xrt,
  title        = {{Xilinx Runtime Library (XRT)}},
  howpublished = {\url{https://www.xilinx.com/products/design-tools/vitis/xrt.html}}
}

@misc{intel_rapl,
  title        = {{Running Average Power Limit – RAPL}},
  howpublished = {\url{https://01.org/blogs/2014/running-average-power-limit-\%E2\%80\%93-rapl}}
}

@misc{intel_cmt_cat,
  title        = {{Intel(R) RDT Software Package}},
  howpublished = {\url{https://github.com/intel/intel-cmt-cat}}
}
@inproceedings {erpc,
author = {Anuj Kalia and Michael Kaminsky and David Andersen},
title = {Datacenter {RPCs} can be General and Fast},
booktitle = {16th USENIX Symposium on Networked Systems Design and Implementation (NSDI 19)},
year = {2019},
isbn = {978-1-931971-49-2},
address = {Boston, MA},
pages = {1--16},
url = {https://www.usenix.org/conference/nsdi19/presentation/kalia},
publisher = {USENIX Association},
month = feb,
}
@inproceedings {btrdb,
author = {Michael P Andersen and David E. Culler},
title = {{BTrDB}: Optimizing Storage System Design for Timeseries Processing},
booktitle = {14th USENIX Conference on File and Storage Technologies (FAST 16)},
year = {2016},
isbn = {978-1-931971-28-7},
address = {Santa Clara, CA},
pages = {39--52},
url = {https://www.usenix.org/conference/fast16/technical-sessions/presentation/andersen},
publisher = {USENIX Association},
month = feb,
}

@misc{stdlist,
  title        = {{C++ standard list container}},
  howpublished = {\url{https://en.cppreference.com/w/cpp/container/list}}
}
@misc{stdforwardlist,
  title        = {{C++ standard forward\_list container}},
  howpublished = {\url{https://en.cppreference.com/w/cpp/container/forward_list}}
}
@misc{stdmap,
  title        = {{C++ standard map container}},
  howpublished = {\url{https://en.cppreference.com/w/cpp/container/map}}
}
@misc{stdset,
  title        = {{C++ standard set container}},
  howpublished = {\url{https://en.cppreference.com/w/cpp/container/set}}
}
@misc{stdmultimap,
  title        = {{C++ standard multimap container}},
  howpublished = {\url{https://en.cppreference.com/w/cpp/container/multimap}}
}
@misc{stdmultiset,
  title        = {{C++ standard multiset container}},
  howpublished = {\url{https://en.cppreference.com/w/cpp/container/multiset}}
}
@misc{googleskiplist,
  title        = {{Google LevelDB}},
  howpublished = {\url{https://github.com/google/leveldb}}
}
@misc{boostbimap,
  title        = {{Boost bimap}},
  howpublished = {\url{https://www.boost.org/doc/libs/1_80_0/libs/bimap/doc/html/index.html}}
}
@misc{boostunorderedmap,
  title        = {{Boost unordered map}},
  howpublished = {\url{https://www.boost.org/doc/libs/1_38_0/doc/html/boost/unordered_map.html}}
}
@misc{boostunorderedset,
  title        = {{Boost unordered set}},
  howpublished = {\url{https://www.boost.org/doc/libs/1_51_0/doc/html/boost/unordered_set.html}}
}
@misc{boostavltree,
  title        = {{Boost AVL tree}},
  howpublished = {\url{https://www.boost.org/doc/libs/1_35_0/doc/html/intrusive/avl_set_multiset.html}}
}
@misc{boostsplaytree,
  title        = {{Boost splay tree}},
  howpublished = {\url{https://www.boost.org/doc/libs/1_35_0/doc/html/intrusive/splay_set_multiset.html}}
}
@misc{boostscapegoattree,
  title        = {{Boost scapegoat tree}},
  howpublished = {\url{https://www.boost.org/doc/libs/1_38_0/doc/html/intrusive/sg_set_multiset.html}}
}

%% Serverless
@article{serverless-survey,
  author = {Castro, Paul and Ishakian, Vatche and Muthusamy, Vinod and Slominski, Aleksander},
  title = {The Rise of Serverless Computing},
  year = {2019},
  volume = {62},
  number = {12},
  journal = {Communications of the ACM},
}

@techreport{berkeley-serverless,
    Author = {Jonas, Eric and Schleier-Smith, Johann and Sreekanti, Vikram and Tsai, Chia-Che and Khandelwal, Anurag and Pu, Qifan and Shankar, Vaishaal and Menezes Carreira, Joao and Krauth, Karl and Yadwadkar, Neeraja and Gonzalez, Joseph and Popa, Raluca Ada and Stoica, Ion and Patterson, David A.},
    Title = {Cloud Programming Simplified: A Berkeley View on Serverless Computing},
    Institution = {EECS Department, University of California, Berkeley},
    Year = {2019},
    Number = {UCB/EECS-2019-3},
}

@article{joe-serverless,
  title={Serverless computing: One step forward, two steps back},
  author={Hellerstein, Joseph M and Faleiro, Jose and Gonzalez, Joseph E and Schleier-Smith, Johann and Sreekanti, Vikram and Tumanov, Alexey and Wu, Chenggang},
  journal={arXiv preprint arXiv:1812.03651},
  year={2018}
}

@misc{serverlesssurvey,
 title = {{State of the Serverless Community Survey Results}},
 howpublished = "\url{https://serverless.com/blog/state-of-serverless-community}",
}

%% Jiffy
@inproceedings{pocket,
  title={Pocket: Elastic ephemeral storage for serverless analytics},
  author={Klimovic, Ana and Wang, Yawen and Stuedi, Patrick and Trivedi, Animesh and Pfefferle, Jonas and Kozyrakis, Christos},
  booktitle={USENIX Symposium on Operating Systems Design and Implementation (OSDI 18)},
  pages={427--444},
  year={2018}
}


@article{memorydisaggregationchallenges,
author = {Aguilera, Marcos K. and Amaro, Emmanuel and Amit, Nadav and Hunhoff, Erika and Yelam, Anil and Zellweger, Gerd},
title = {Memory Disaggregation: Why Now and What Are the Challenges},
year = {2023},
issue_date = {June 2023},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {57},
number = {1},
issn = {0163-5980},
url = {https://doi.org/10.1145/3606557.3606563},
doi = {10.1145/3606557.3606563},
abstract = {Hardware disaggregation has emerged as one of the most fundamental shifts in how we build computer systems over the past decades. While disaggregation has been successful for several types of resources (storage, power, and others), memory disaggregation has yet to happen. We make the case that the time for memory disaggregation has arrived. We look at past successful disaggregation stories and learn that their success depended on two requirements: addressing a burning issue and being technically feasible. We examine memory disaggregation through this lens and find that both requirements are finally met. Once available, memory disaggregation will require software support to be used effectively. We discuss some of the challenges of designing an operating system that can utilize disaggregated memory for itself and its applications.},
journal = {SIGOPS Oper. Syst. Rev.},
month = {jun},
pages = {38–46},
numpages = {9}
}



@inproceedings{remotememory,
  author = {Aguilera, Marcos K. and Amit, Nadav and Calciu, Irina and Deguillard, Xavier and Gandhi, Jayneel and Subrahmanyam, Pratap and Suresh, Lalith and Tati, Kiran and Venkatasubramanian, Rajesh and Wei, Michael},
  title = {{Remote Memory in the Age of Fast Networks}},
  year = {2017},
  booktitle = {SoCC},
}

@inproceedings{fastswap,
  author = {Amaro, Emmanuel and Branner-Augmon, Christopher and Luo, Zhihong and Ousterhout, Amy and Aguilera, Marcos K. and Panda, Aurojit and Ratnasamy, Sylvia and Shenker, Scott},
  title = {{Can Far Memory Improve Job Throughput?}},
  year = {2020},
  booktitle = {EuroSys},
}

@inproceedings{farm,
  author = {Dragojevi{\'c}, Aleksandar and Narayanan, Dushyanth and Hodson, Orion and Castro, Miguel},
  title = {{FaRM: Fast Remote Memory}},
  booktitle = {NSDI},
  year = {2014}
}


@inproceedings{remote_ds_hotos19,
  title = {Designing Far Memory Data Structures: {{Think}} Outside the Box},
  booktitle = {Proceedings of the Workshop on Hot Topics in Operating Systems},
  author = {Aguilera, Marcos K. and Keeton, Kimberly and Novakovic, Stanko and Singhal, Sharad},
  year = {2019},
  pages = {120--126},
}

@inproceedings{storm_systor_19,
author = {Novakovic, Stanko and Shan, Yizhou and Kolli, Aasheesh and Cui, Michael and Zhang, Yiying and Eran, Haggai and Pismenny, Boris and Liss, Liran and Wei, Michael and Tsafrir, Dan and Aguilera, Marcos},
title = {{Storm: A Fast Transactional Dataplane for Remote Data Structures}},
year = {2019},
booktitle = {SYSTOR},
pages = {97–108},
numpages = {12}
}

@inproceedings{kayak_nsdi_21,
author = {Jie You and Jingfeng Wu and Xin Jin and Mosharaf Chowdhury},
title = {{Ship Compute or Ship Data? Why Not Both?}},
booktitle = {NSDI},
year = {2021},
pages = {633--651}
}


@inproceedings{starling,
author = {Perron, Matthew and Castro Fernandez, Raul and DeWitt, David and Madden, Samuel},
title = {Starling: A Scalable Query Engine on Cloud Functions},
year = {2020},
isbn = {9781450367356},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3318464.3380609},
doi = {10.1145/3318464.3380609},
abstract = {Much like on-premises systems, the natural choice for running database analytics workloads in the cloud is to provision a cluster of nodes to run a database instance. However, analytics workloads are often bursty or low volume, leaving clusters idle much of the time, meaning customers pay for compute resources even when underutilized. The ability of cloud function services, such as AWS Lambda or Azure Functions, to run small, fine granularity tasks make them appear to be a natural choice for query processing in such settings. But implementing an analytics system on cloud functions comes with its own set of challenges. These include managing hundreds of tiny stateless resource-constrained workers, handling stragglers, and shuffling data through opaque cloud services. In this paper we present Starling, a query execution engine built on cloud function services that employs a number of techniques to mitigate these challenges, providing interactive query latency at a lower total cost than provisioned systems with low-to-moderate utilization. In particular, on a 1TB TPC-H dataset in cloud storage, Starling is less expensive than the best provisioned systems for workloads when queries arrive 1 minute apart or more. Starling also has lower latency than competing systems reading from cloud object stores and can scale to larger datasets.},
booktitle = {Proceedings of the 2020 ACM SIGMOD International Conference on Management of Data},
pages = {131–141},
numpages = {11},
keywords = {cloud, OLAP, serverless, FAAS},
location = {Portland, OR, USA},
series = {SIGMOD '20}
}

@inproceedings {shuffling,
author = {Qifan Pu and Shivaram Venkataraman and Ion Stoica},
title = {Shuffling, Fast and Slow: Scalable Analytics on Serverless Infrastructure},
booktitle = {16th USENIX Symposium on Networked Systems Design and Implementation (NSDI 19)},
year = {2019},
isbn = {978-1-931971-49-2},
address = {Boston, MA},
pages = {193--206},
url = {https://www.usenix.org/conference/nsdi19/presentation/pu},
publisher = {USENIX Association},
month = feb
}

@inproceedings{cirrus,
author = {Carreira, Joao and Fonseca, Pedro and Tumanov, Alexey and Zhang, Andrew and Katz, Randy},
title = {Cirrus: A Serverless Framework for End-to-End ML Workflows},
year = {2019},
isbn = {9781450369732},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3357223.3362711},
doi = {10.1145/3357223.3362711},
abstract = {Machine learning (ML) workflows are extremely complex. The typical workflow consists of distinct stages of user interaction, such as preprocessing, training, and tuning, that are repeatedly executed by users but have heterogeneous computational requirements. This complexity makes it challenging for ML users to correctly provision and manage resources and, in practice, constitutes a significant burden that frequently causes over-provisioning and impairs user productivity. Serverless computing is a compelling model to address the resource management problem, in general, but there are numerous challenges to adopt it for existing ML frameworks due to significant restrictions on local resources.This work proposes Cirrus---an ML framework that automates the end-to-end management of datacenter resources for ML workflows by efficiently taking advantage of serverless infrastructures. Cirrus combines the simplicity of the serverless interface and the scalability of the serverless infrastructure (AWS Lambdas and S3) to minimize user effort. We show a design specialized for both serverless computation and iterative ML training is needed for robust and efficient ML training on serverless infrastructure. Our evaluation shows that Cirrus outperforms frameworks specialized along a single dimension: Cirrus is 100x faster than a general purpose serverless system [36] and 3.75x faster than specialized ML frameworks for traditional infrastructures [49].},
booktitle = {Proceedings of the ACM Symposium on Cloud Computing},
pages = {13–24},
numpages = {12},
keywords = {Serverless, Machine Learning, Distributed Computing},
location = {Santa Cruz, CA, USA},
series = {SoCC '19}
}

@inproceedings {elasticquery,
author = {Midhul Vuppalapati and Justin Miron and Rachit Agarwal and Dan Truong and Ashish Motivala and Thierry Cruanes},
title = {Building An Elastic Query Engine on Disaggregated Storage },
booktitle = {17th USENIX Symposium on Networked Systems Design and Implementation (NSDI 20)},
year = {2020},
isbn = {978-1-939133-13-7},
address = {Santa Clara, CA},
pages = {449--462},
url = {https://www.usenix.org/conference/nsdi20/presentation/vuppalapati},
publisher = {USENIX Association},
month = feb
}

@inproceedings {qoop,
author = {Kshiteej Mahajan and Mosharaf Chowdhury and Aditya Akella and Shuchi Chawla},
title = {Dynamic Query {Re-Planning} using {QOOP}},
booktitle = {13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18)},
year = {2018},
isbn = {978-1-939133-08-3},
address = {Carlsbad, CA},
pages = {253--267},
url = {https://www.usenix.org/conference/osdi18/presentation/mahajan},
publisher = {USENIX Association},
month = oct
}

@inproceedings{cxleurosys,
author = {Tang, Yupeng and Zhou, Ping and Zhang, Wenhui and Hu, Henry and Yang, Qirui and Xiang, Hao and Liu, Tongping and Shan, Jiaxin and Huang, Ruoyun and Zhao, Cheng and Chen, Cheng and Zhang, Hui and Liu, Fei and Zhang, Shuai and Ding, Xiaoning and Chen, Jianjun},
title = {Exploring Performance and Cost Optimization with ASIC-Based CXL Memory},
year = {2024},
isbn = {9798400704376},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3627703.3650061},
doi = {10.1145/3627703.3650061},
abstract = {As memory-intensive applications continue to drive the need for advanced architectural solutions, Compute Express Link (CXL) has risen as a promising interconnect technology that enables seamless high-speed, low-latency communication between host processors and various peripheral devices. In this study, we explore the application performance of ASIC CXL memory in various data-center scenarios. We then further explore multiple potential impacts (e.g., throughput, latency, and cost reduction) of employing CXL memory via carefully designed policies and strategies. Our empirical results show the high potential of CXL memory, reveal multiple intriguing observations of CXL memory and contribute to the wide adoption of CXL memory in real-world deployment environments. Based on our benchmarks, we also develop an Abstract Cost Model that can estimate the cost benefit from using CXL memory.},
booktitle = {Proceedings of the Nineteenth European Conference on Computer Systems},
pages = {818–833},
numpages = {16},
keywords = {CXL-Memory, Datacenters, Memory Management, Operating Systems, measurement},
location = {<conf-loc>, <city>Athens</city>, <country>Greece</country>, </conf-loc>},
series = {EuroSys '24}
}