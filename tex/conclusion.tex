\chapter{Conclusion}
\label{chap:conclusion}

In this dissertation, we adopt a top-down approach to explore optimal memory management solutions across three key layers of the cloud stack: Service, Operating System (OS), and Hardware. Using a software-hardware co-design strategy, we address three key challenges of disaggregated memory—\textbf{C1: Inefficient Resource Multiplexing}, \textbf{C2: High-Latency Memory Access}, and \textbf{C3: Diverse Interconnect Performance}—while achieving the main requirements of \textbf{R1: Transparency}, \textbf{R2: Application Performance}, and \textbf{R3: Resource Utilization}.

At the Service layer, \jiffy addresses \textbf{C1} by enabling efficient multiplexing of memory resources across jobs, allowing dynamic scaling without prior knowledge of data sizes. By allocating memory in small, fixed-size blocks, \jiffy ensures \textbf{R3}, optimizing resource utilization through efficient sharing of fast memory and reducing reliance on slower storage like S3. Additionally, \jiffy achieves \textbf{R1} by providing transparent memory management, allowing serverless analytics applications to scale resources dynamically without significant code modifications.

In the OS layer, we propose \mind, an in-network memory management system that tackles \textbf{C2} by leveraging programmable switch ASICs to mitigate interconnect overhead and provide low-latency access to disaggregated memory, thus meeting \textbf{R2}. Moreover, \pulse further reduces latency by offloading pointer traversal workloads to near-memory processors, enabling high-throughput operations on disaggregated memory. Both \mind and \pulse maintain \textbf{R1} by transparently handling memory management, while optimizing \textbf{R3} by efficiently managing resources across distributed memory nodes.

At the Hardware layer, we examine the role of next-generation interconnects, specifically CXL, in overcoming \textbf{C3}. Our evaluation shows how CXL opens new possibilities for disaggregated memory while ensuring \textbf{R2} by enabling effective management of tiered memory and adapting policies to suit applications with varying performance characteristics. Additionally, we develop an Abstract Cost Model to guide TCO savings, helping cloud providers maximize \textbf{R3} by designing infrastructure that balances performance and cost efficiency.

In conclusion, this dissertation solves the challenges of disaggregated memory architectures by proposing solutions that span the Service, OS, and Hardware layers. By addressing \textbf{C1}, \textbf{C2}, and \textbf{C3}, we successfully achieve \textbf{R1}, \textbf{R2}, and \textbf{R3}, paving the way for more efficient and scalable cloud infrastructures in data-centric environments.
