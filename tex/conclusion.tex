\chapter{Conclusion}
\label{chap:conclusion}

In this dissertation, we adopt a top-down approach to explore optimal memory management solutions across three key layers of the cloud stack: Service, Operating System (OS), and Hardware. Using a software-hardware co-design strategy, we address three key challenges of disaggregated memory: inefficient resource multiplexing, high-latency memory access, and the diverse performance characteristics of next-generation interconnects. Simultaneously, we meet the main requirements of achieving transparency, ensuring good application performance, and optimizing resource utilization.

At the Service layer, \jiffy addresses the challenge of inefficient resource multiplexing by enabling efficient sharing of memory resources across jobs, allowing dynamic scaling without prior knowledge of data sizes. By allocating memory in small, fixed-size blocks, \jiffy optimizes resource utilization by facilitating efficient sharing of fast memory and reducing reliance on slower storage like S3. Additionally, \jiffy provides transparent memory management, allowing serverless analytics applications to scale resources dynamically without requiring significant code modifications.

In the OS layer, we propose \pulse, a near-memory processor that tackles the challenge of high-latency memory access by offloading pointer traversal workloads to near-memory processors, significantly reducing interconnect overhead and enabling high-throughput operations on disaggregated memory. \pulse ensures good application performance by providing low-latency access to disaggregated memory. Additionally, \pulse maintains transparency by managing memory without requiring application re-implementation, while also optimizing resource utilization by efficiently managing resources across distributed memory nodes.


At the Hardware layer, we examine the role of next-generation interconnects, specifically CXL, in overcoming the challenge of diverse interconnect performance. Our evaluation demonstrates how CXL opens new possibilities for disaggregated memory while ensuring good application performance by enabling effective management of tiered memory and adapting policies to suit applications with varying performance characteristics. Additionally, we develop an Abstract Cost Model to guide total cost of ownership (TCO) savings, helping cloud providers optimize resource utilization by designing infrastructure that balances performance and cost efficiency.

In conclusion, this dissertation addresses the challenges of disaggregated memory architectures by proposing solutions that span the Service, OS, and Hardware layers. By solving the issues of inefficient resource multiplexing, high-latency memory access, and diverse interconnect performance, we achieve transparency, ensure good application performance, and optimize resource utilization, paving the way for more efficient and scalable cloud infrastructures in data-centric environments.
